{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.cm as cm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, OrdinalEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Exam_Performance_Data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "\n",
    "print(data.info(verbose=True))  # to check for null entries\n",
    "\n",
    "# no null entries where found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicates, since no IDs where given in the dataset\n",
    "\n",
    "duplicates = data.duplicated().sum()\n",
    "\n",
    "print(duplicates)\n",
    "\n",
    "# one duplicate has been found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ec32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)  # duplicate will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test scores will be summarized into a meta score, it might be interesting also to see which score is the most...\n",
    "# ...impactful\n",
    "data[\"Test_Meta_Score\"] = data[\"math score\"] + data[\"reading score\"] + data[\"writing score\"]\n",
    "\n",
    "# test preparation will be converted into a simple binary (dummy) variable 0/1, since its impact can be assumed...\n",
    "# ...quite clearly; lunch was not changed accordingly, since it is not as clear\n",
    "data[\"test preparation course\"] = data[\"test preparation course\"].replace({\"completed\": 1, \"none\": 0})\n",
    "\n",
    "# transforming education data for the one hot encoding\n",
    "\n",
    "data['parental level of education'] = data['parental level of education'].replace({'some high school':'some_high_school','high school': 'high_school','some college':'some_college',\"associate's degree\":\"associate's_degree\",\"bachelor's degree\":\"bachelor's_degree\",\"master's degree\":\"master's_degree\"})\n",
    "\n",
    "categorical_cols = ['gender', 'race/ethnicity', 'lunch']\n",
    "ordinal_cols = ['parental level of education']\n",
    "numerical_cols = ['test preparation course', 'math score', 'reading score', 'writing score', 'Test_Meta_Score']\n",
    "# test preperation course is an already one hot encoded variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08845dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transformer for each data type\n",
    "# Transfomer for categorical data based on OHC\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\", sparse=False))\n",
    "])\n",
    "\n",
    "# Encoding of ordinal data\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    (\"encoder\", OrdinalEncoder(categories=[['some_high_school','high_school','some_college',\"associate's_degree\",\"bachelor's_degree\",\"master's_degree\"]]))\n",
    "])\n",
    "\n",
    "# Powertransformer normalises data with the assumtption that data is normaly distributed\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"transformer\", PowerTransformer())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b86af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "        ('ord', ordinal_transformer, ordinal_cols),\n",
    "        ('num', numerical_transformer, numerical_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "pipeline.fit(data)\n",
    "transformed_data = pipeline.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df from transformed data to have a better understanding of data\n",
    "transformed_df = pd.DataFrame(transformed_data, columns = pipeline.fit(data).get_feature_names_out().tolist())\n",
    "print(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers\n",
    "detector = ECOD()\n",
    "detector.fit(transformed_df)\n",
    "outliers = detector.predict(transformed_df)\n",
    "transformed_df['outliers'] = outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63de3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_outliers = transformed_df[transformed_df['outliers']==0].drop([\"outliers\"], axis = 1)\n",
    "data_with_outliers = transformed_df.copy().drop([\"outliers\"], axis = 1)\n",
    "\n",
    "km = KMeans(init=\"k-means++\", random_state=0, n_init=\"auto\")\n",
    "visualizer = KElbowVisualizer(km, k=(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.fit(data_no_outliers)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c113386",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3, init='k-means++', random_state=42, n_init = 10)\n",
    "clusters = km.fit_predict(data_no_outliers)\n",
    "\n",
    "print(km.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_outliers['cluster'] = clusters\n",
    "\n",
    "## PCA to reduce dimensions and visualise clusters differentiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce data to 2D\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data_no_outliers)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(data_pca[:, 0], data_pca[:, 1], c=clusters, cmap='rainbow', edgecolor='k', s=100)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('KMeans Clustering with 3 Clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f187872",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA to reduce dimensions and visualise clusters differentiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce data to 3D\n",
    "pca = PCA(n_components=3)\n",
    "data_pca = pca.fit_transform(data_no_outliers)\n",
    "\n",
    "# 3D-Plot\n",
    "graph = plt.figure()\n",
    "axis = graph.add_subplot(projection=\"3d\")\n",
    "xdata = data_pca[:, 0]\n",
    "ydata = data_pca[:, 1]\n",
    "zdata = data_pca[:, 2]\n",
    "axis.scatter3D(xdata, ydata, zdata, c=clusters, cmap = \"rainbow\", s=10)\n",
    "axis.set_xlabel(\"Principal Component 1\")\n",
    "axis.set_ylabel(\"Principal Component 2\")\n",
    "axis.set_zlabel(\"Principal Component 3\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
